{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Weight Initialization\n",
    "def init_weights(shape):\n",
    "    weights = tf.random_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forwardprop(X, w_1, w_2):\n",
    "    \n",
    "    yhat = tf.nn.softmax(tf.matmul(tf.matmul(X, w_1), w_2))\n",
    "    \n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Layer's sizes\n",
    "x_size = 256  \n",
    "h_size = 20                \n",
    "y_size = 256   \n",
    "\n",
    "# Architecture\n",
    "X = tf.placeholder(\"float\", shape=[None, x_size])\n",
    "y = tf.placeholder(\"float\", shape=[None, y_size])\n",
    "\n",
    "\n",
    "w_1 = init_weights((x_size, h_size))\n",
    "w_2 = init_weights((h_size, x_size))\n",
    "\n",
    "\n",
    "# Forward Propogation\n",
    "yhat = forwardprop(X, w_1, w_2)\n",
    "predict = tf.nn.softmax(yhat)\n",
    "\n",
    "\n",
    "# Backward propagation\n",
    "cost    = tf.reduce_mean(tf.losses.softmax_cross_entropy(y, yhat))\n",
    "updates = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im2via\n",
      "m_meroyan\n",
      "padmapriyapvld\n",
      "testoftiramisu\n",
      "yandajl28\n"
     ]
    }
   ],
   "source": [
    "# Run SGD\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Saver\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "rootdir = '/Volumes/SP PHD U3/SeniorProject/KestrelCapstone/HackerRank/download/30-arrays'\n",
    "dirs = next(os.walk(rootdir))[1]\n",
    "train_dirs = dirs[10:]\n",
    "test_dirs = dirs[:10]\n",
    "for _ in range(1):\n",
    "    for d in train_dirs:\n",
    "        os.chdir(rootdir + '/' + d)\n",
    "        try:\n",
    "            train_X = pd.read_csv('X3.csv')\n",
    "            train_y = pd.read_csv('Y3.csv')\n",
    "        except:\n",
    "            print(d)\n",
    "            continue\n",
    "        # Train with each example\n",
    "        for i in range(len(train_X)):\n",
    "            sess.run(updates, feed_dict={X: (train_X[i: i + 1]), y: (train_y[i: i + 1])})\n",
    "        os.chdir('..')\n",
    "    saver.save(sess, \"/Volumes/SP PHD U3/SeniorProject/models340/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Volumes/SP PHD U3/SeniorProject/models/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# restore previous model\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "saver.restore(sess, \"/Volumes/SP PHD U3/SeniorProject/models/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_problem(prob_dir):\n",
    "    dirs = next(os.walk(prob_dir))[1]\n",
    "    train_dirs = dirs[10:]\n",
    "    test_dirs = dirs[:10]\n",
    "    for d in train_dirs:\n",
    "        os.chdir(prob_dir + '/' + d)\n",
    "        try:\n",
    "            train_X = pd.read_csv('X3.csv')\n",
    "            train_y = pd.read_csv('Y3.csv')\n",
    "        except:\n",
    "            continue\n",
    "        # Train with each example\n",
    "        for i in range(len(train_X)):\n",
    "            sess.run(updates, feed_dict={X: (train_X[i: i + 1]), y: (train_y[i: i + 1])})\n",
    "        os.chdir('..')\n",
    "    saver.save(sess, \"/Volumes/SP PHD U3/SeniorProject/models340/model.ckpt\")\n",
    "        \n",
    "    # Get Train Accuracy\n",
    "    train_accuracy = 0\n",
    "    for d in train_dirs:\n",
    "        os.chdir(prob_dir + '/' + d)\n",
    "        try:\n",
    "            train_X = pd.read_csv('X3.csv', header = None)\n",
    "            train_y = pd.read_csv('Y3.csv', header = None)\n",
    "        except:\n",
    "            continue\n",
    "        cmp_y = [train_y[row].argmax() for row in train_y]\n",
    "        train_accuracy += np.mean([x == y for x, y in zip(cmp_y, np.argmax(sess.run(predict, feed_dict={X: train_X, y: train_y}), axis = 1))])\n",
    "        os.chdir('..')\n",
    "    print(\"Train Accuracy:\", train_accuracy/len(train_dirs))\n",
    "    \n",
    "    # Get Test Accuracy\n",
    "    test_accuracy = 0\n",
    "    for d in test_dirs:\n",
    "        os.chdir(prob_dir + '/' + d)\n",
    "        try:\n",
    "            test_X = pd.read_csv('X3.csv', header = None)\n",
    "            test_y = pd.read_csv('Y3.csv', header = None)\n",
    "        except:\n",
    "            continue\n",
    "        cmp_y = [test_y[row].argmax() for row in test_y]\n",
    "        test_accuracy += np.mean([x == y for x, y in zip(cmp_y, np.argmax(sess.run(predict, feed_dict={X: test_X, y: test_y}), axis = 1))])\n",
    "        os.chdir('..')\n",
    "    print(\"Test Accuracy:\", test_accuracy/len(test_dirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 30-arrays :\n",
      "Train Accuracy: 0.1399045138888889\n",
      "Test Accuracy: 0.13828125\n",
      "training with 30-class-vs-instance :\n",
      "Train Accuracy: 0.0\n",
      "Test Accuracy: 0.0\n",
      "training with 30-conditional-statements :\n",
      "Train Accuracy: 0.8464719742063492\n",
      "Test Accuracy: 0.6796875\n",
      "training with 30-data-types :\n",
      "Train Accuracy: 0.0\n",
      "Test Accuracy: 0.0\n",
      "training with 30-hello-world :\n",
      "Train Accuracy: 0.8978020038908556\n",
      "Test Accuracy: 0.9043134043134042\n",
      "training with 30-loops :\n",
      "Train Accuracy: 0.843584656084656\n",
      "Test Accuracy: 0.672265625\n",
      "training with 30-operators :\n",
      "Train Accuracy: 0.0\n",
      "Test Accuracy: 0.0\n",
      "training with 30-review-loop :\n",
      "Train Accuracy: 0.7580501818783069\n",
      "Test Accuracy: 0.64609375\n",
      "training with quicksort3 :\n",
      "Train Accuracy: 0.6418105544747081\n",
      "Test Accuracy: 0.533203125\n",
      "training with s10-least-square-regression-line :\n",
      "Train Accuracy: 0.04762916666666666\n",
      "Test Accuracy: 0.0\n",
      "training with s10-multiple-linear-regression :\n",
      "Train Accuracy: 0.47246799698795183\n",
      "Test Accuracy: 0.374609375\n",
      "training with s10-pearson-correlation-coefficient :\n",
      "Train Accuracy: 0.21054456360946747\n",
      "Test Accuracy: 0.22890625\n",
      "training with s10-spearman-rank-correlation-coefficient :\n",
      "Train Accuracy: 0.014552156690140846\n",
      "Test Accuracy: 0.0\n",
      "training with s10-the-central-limit-theorem-3 :\n",
      "Train Accuracy: 0.11028989538571722\n",
      "Test Accuracy: 0.083984375\n",
      "training with tutorial-intro :\n",
      "Train Accuracy: 0.7051975642230577\n",
      "Test Accuracy: 0.684375\n"
     ]
    }
   ],
   "source": [
    "rootdir = '/Volumes/SP PHD U3/SeniorProject/KestrelCapstone/HackerRank/download/'\n",
    "problems = next(os.walk(rootdir))[1]\n",
    "for problem in problems:\n",
    "    print(\"training with\", problem, \":\")\n",
    "    train_problem(rootdir + problem)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vec(ins, word_vecs):\n",
    "    arr = np.zeros(256, dtype=int)\n",
    "    arr[ins] = 1\n",
    "    arr = arr.reshape((1, 256))\n",
    "    word_vecs = sess.run(w_1)\n",
    "    return arr.dot(word_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec_lookup(vec, word_vecs):\n",
    "    distances = [np.sum((x - vec) ** 2) for x in word_vecs]\n",
    "    return [hex(distances.index(i)) for i in sorted(distances)[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_vec(insns, word_vecs, sse = False):\n",
    "    test = get_vec(insns[0], word_vecs) + get_vec([1], word_vecs) - get_vec([2], word_vecs)\n",
    "    if sse:\n",
    "        return np.sum((get_vec(insns[3], word_vecs) - test) ** 2)\n",
    "    else:\n",
    "        return insns[3] in vec_lookup(test, word_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vecs = sess.run(w_1)\n",
    "vec_tests = [[0x19, 0x2b, 0x3a, 0x4c], # aload + aload_1 - astore = astore_1 1.\n",
    "             [0x19, 0x2a, 0x3a, 0x4b], # aload + aload_0 - astore = astore_0 2.\n",
    "             [0x19, 0x2c, 0x3a, 0x4d], # aload + aload_2 - astore = astore_2 3.\n",
    "             [0x19, 0x2d, 0x3a, 0x4e], # aload + aload_3 - astore = astore_3 4.\n",
    "             [0x33, 0x54, 0x55, 0x34], # baload + bastore - castore = caload 5.\n",
    "             [0x63, 0x31, 0x62, 0x30], # dadd + daload - fadd = faload 6.\n",
    "             [0x60, 0x2e, 0x61, 0x2f], # iadd + iaload - ladd = laload 7.\n",
    "             [0x98, 0x97, 0x96, 0x95], # dcmpg + dcmpl - fcmpg = fcmpl 8.\n",
    "             [0x52, 0x0e, 0x51, 0x0b], # dastore + dconst_0 - fastore = fconst_0 9.\n",
    "             [0x4f, 0x04, 0x50, 0x0a], # iastore + iconst_0 - lastore = lconst_0 10.\n",
    "             [0x0f, 0x6f, 0x0c, 0x6e], # dconst_1 + ddiv - fconst_1 = fdiv 11.\n",
    "             [0x04, 0x6c, 0x0a, 0x6d], # iconst_1 + idiv - lconst_1 = ldiv 12.\n",
    "             [0x18, 0x26, 0x17, 0x22], # dload + dload_0 - fload = fload_0 13.\n",
    "             [0x15, 0x1a, 0x16, 0x1e], # iload + iload_0 - lload = lload_0 14.\n",
    "             [0x27, 0x28, 0x23, 0x24], # dload_1 + dload_2 - fload_1 = fload_2 15.\n",
    "             [0x1b, 0x1c, 0x1f, 0x20], # iload_1 + iload_2 - lload_1 = lload_2 16.\n",
    "             [0x29, 0x6b, 0x25, 0x6a], # dload_3 + dmul - fload_3 = fmul 17.\n",
    "             [0x1d, 0x68, 0x21, 0x69], # iload_3 + imul - lload_3 = lmul 18.\n",
    "             [0x77, 0x73, 0x76, 0x72], # dneg + drem - fneg = frem 19.\n",
    "             [0x74, 0x70, 0x75, 0x71], # ineg + irem - lneg = lrem 20.\n",
    "             [0xaf, 0x39, 0xae, 0x38], # dreturn - dstore + freturn = fstore 21.\n",
    "             [0xac, 0x36, 0xad, 0x37], # ireturn - istore + lreturn = lstore 22.\n",
    "             [0x47, 0x48, 0x43, 0x44], # dstore_0 + dstore_1 - fstore_0 = fstore_1 23.\n",
    "             [0x3b, 0x3c, 0x3f, 0x40], # istore_0 + istore_1 - lstore_0 = lstore_1 24.\n",
    "             [0x49, 0x4a, 0x45, 0x46], # dstore_2 + dstore_3 - fstore_2 = fstore_3 25.\n",
    "             [0x3d, 0x3e, 0x41, 0x42], # istore_2 + istore_3 - lstore_2 = lstore_3 26.\n",
    "             [0x4a, 0x67, 0x46, 0x66], # dstore_3 - dsub + fstore_3 = fsub 27.\n",
    "             [0x3e, 0x64, 0x42, 0x65], # istore_3 - isub + lstore_3 = lsub 28.\n",
    "            ] \n",
    "sum([test_vec(test, word_vecs, sse=True) for test in vec_tests])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
